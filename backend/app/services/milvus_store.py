from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
from app.core.settings import settings

def connect():
    connections.connect(alias="default", host=settings.milvus_host, port=str(settings.milvus_port))

def ensure_collection(dim: int) -> Collection:
    connect()
    name = settings.milvus_collection

    # --- QUAN TR·ªåNG: N·∫æU MU·ªêN RESET DB TH√å B·ªé COMMENT D√íNG D∆Ø·ªöI ---
    # utility.drop_collection(name) 
    
    if utility.has_collection(name):
        col = Collection(name)
        col.load()
        return col

    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name="document_id", dtype=DataType.VARCHAR, max_length=128),
        FieldSchema(name="chunk_id", dtype=DataType.VARCHAR, max_length=128),
        
        # --- TH√äM 2 TR∆Ø·ªúNG M·ªöI CHO HIERARCHICAL ---
        FieldSchema(name="level", dtype=DataType.VARCHAR, max_length=50),       # "fine" / "coarse"
        FieldSchema(name="parent_id", dtype=DataType.VARCHAR, max_length=128),  # ID c·ªßa chunk cha (n·∫øu c√≥)
        # ------------------------------------------

        FieldSchema(name="page_start", dtype=DataType.INT32),
        FieldSchema(name="page_end", dtype=DataType.INT32),
        FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dim),
    ]
    schema = CollectionSchema(fields, description="PDF chunks for RAG")
    col = Collection(name, schema)

    col.create_index(
        field_name="embedding",
        index_params={
            "index_type": "HNSW",
            "metric_type": "IP",
            "params": {"M": 16, "efConstruction": 200},
        },
    )
    col.load()
    return col

def insert_chunks(col: Collection, rows: list[dict]):
    # C·∫ßn ƒë·∫£m b·∫£o th·ª© t·ª± fields kh·ªõp v·ªõi Schema ·ªü tr√™n
    entities = [
        [r["document_id"] for r in rows],
        [r["chunk_id"] for r in rows],
        
        # --- INSERT DATA CHO 2 TR∆Ø·ªúNG M·ªöI ---
        # D√πng .get() ƒë·ªÉ tr√°nh l·ªói n·∫øu chunk c≈© kh√¥ng c√≥ key n√†y
        [r.get("level", "standard") for r in rows], 
        [r.get("parent_id") or "" for r in rows], # L∆∞u √Ω: Milvus chu·ªói th√¨ n√™n ƒë·ªÉ "" thay v√¨ None
        # ------------------------------------

        [r["page_start"] for r in rows],
        [r["page_end"] for r in rows],
        [r["text"] for r in rows],
        [r["embedding"] for r in rows],
    ]
    col.insert(entities)
    col.flush()

def search(col: Collection, query_vec: list[float], topk: int = 30) -> list[dict]:
    res = col.search(
        data=[query_vec],
        anns_field="embedding",
        param={"metric_type": "IP", "params": {"ef": 64}},
        limit=topk,
        # --- L·∫§Y TH√äM LEVEL V√Ä PARENT_ID KHI SEARCH ---
        output_fields=["document_id", "chunk_id", "level", "parent_id", "page_start", "page_end", "text"],
    )

    hits = []
    for h in res[0]:
        entity = h.entity
        hits.append({
            "score": float(h.score),
            "document_id": entity.get("document_id"),
            "chunk_id": entity.get("chunk_id"),
            
            # Map tr∆∞·ªùng m·ªõi ra k·∫øt qu·∫£
            "level": entity.get("level"),
            "parent_id": entity.get("parent_id"),
            
            "page_start": int(entity.get("page_start")),
            "page_end": int(entity.get("page_end")),
            "text": entity.get("text"),
        })
    return hits

# --- H√ÄM M·ªöI: D√ôNG ƒê·ªÇ L·∫§Y TEXT C·ª¶A PARENT ---
def get_chunk_by_id(col: Collection, chunk_id: str):
    """
    Truy v·∫•n tr·ª±c ti·∫øp chunk theo ID (D√πng cho Hierarchical Retrieval)
    """
    if not chunk_id:
        return None
        
    res = col.query(
        expr=f'chunk_id == "{chunk_id}"',
        output_fields=["text", "page_start", "page_end", "chunk_id", "level"],
        limit=1
    )
    
    if res:
        return res[0] # Tr·∫£ v·ªÅ dict ch·ª©a text
    return None

# Th√™m v√†o cu·ªëi file app/services/milvus_store.py

def get_all_documents(col: Collection):
    """
    H√†m n√†y l·∫•y TO√ÄN B·ªò d·ªØ li·ªáu ƒë·ªÉ n·∫°p cho BM25.
    ƒê·ªìng th·ªùi gom c√°c tr∆∞·ªùng l·∫ª (level, page...) v√†o dict 'metadata' ƒë·ªÉ kh·ªõp v·ªõi logic Pipeline.
    """
    try:
        col.load()
        
        # Query l·∫•y t·∫•t c·∫£ record c√≥ chunk_id kh√°c r·ªóng
        # L∆∞u √Ω: Milvus gi·ªõi h·∫°n m·∫∑c ƒë·ªãnh 16384 d√≤ng. N·∫øu nhi·ªÅu h∆°n ph·∫£i d√πng iterator.
        results = col.query(
            expr="chunk_id != ''", 
            output_fields=["chunk_id", "text", "document_id", "level", "parent_id", "page_start", "page_end"],
            limit=10000 
        )
        
        # CHUY·ªÇN ƒê·ªîI C·∫§U TR√öC (QUAN TR·ªåNG)
        # Schema c·ªßa b·∫°n l√† c√°c tr∆∞·ªùng l·∫ª, nh∆∞ng Pipeline l·∫°i c·∫ßn 'metadata'
        # Ta s·∫Ω t·ª± t·∫°o 'metadata' gi·∫£ l·∫≠p ·ªü ƒë√¢y.
        formatted_docs = []
        for r in results:
            formatted_docs.append({
                "chunk_id": r["chunk_id"],
                "text": r["text"],
                "metadata": {
                    "document_id": r["document_id"],
                    "level": r.get("level", "standard"),
                    "parent_id": r.get("parent_id", ""),
                    "page_start": r["page_start"],
                    "page_end": r["page_end"]
                }
            })
            
        print(f"üìö ƒê√£ load {len(formatted_docs)} documents cho BM25.")
        return formatted_docs

    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi load documents cho BM25: {e}")
        return []